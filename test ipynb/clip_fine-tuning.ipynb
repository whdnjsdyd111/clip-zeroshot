{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e1e6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset, template):\n",
    "        self.dataset = dataset\n",
    "        self.classes = dataset.classes\n",
    "        \n",
    "        prompt = []\n",
    "        \n",
    "        for data in tqdm(dataset):\n",
    "            prompt.append(template.format(self.classes[data[1]])) \n",
    "        \n",
    "        self.prompt = clip.tokenize(prompt)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx][0]\n",
    "        label = self.dataset[idx][1]\n",
    "        text = self.prompt[idx]\n",
    "        \n",
    "        return image, label, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "680c03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroshot_classifier(classnames, templates):\n",
    "    with torch.no_grad():\n",
    "        zeroshot_weights = []\n",
    "        \n",
    "        for classname in tqdm(classnames):\n",
    "            texts = [template.format(classname) for template in templates]\n",
    "            texts = clip.tokenize(texts).cuda()\n",
    "            \n",
    "            class_embeddings = model.encode_text(texts)\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            class_embedding = class_embeddings.mean(dim=0)\n",
    "            class_embedding /= class_embedding.norm()\n",
    "            \n",
    "            zeroshot_weights.append(class_embedding)\n",
    "            \n",
    "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
    "        \n",
    "    return zeroshot_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8014597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 171.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 500/500 [00:56<00:00,  8.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 189.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.82it/s]\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          110     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.15129D+05    |proj g|=  2.95666D+02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  110     49     53      1     0     0   3.518D-01   8.639D+04\n",
      "  F =   86393.929816777047     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Accuracy = 88.920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Load the dataset\n",
    "train = CIFAR10('./cifar10_data', download=True, train=True, transform=preprocess)\n",
    "test = CIFAR10('./cifar10_data', download=True, train=False, transform=preprocess)\n",
    "\n",
    "prompt = ['this is a photo of {}']\n",
    "\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    weights = zeroshot_classifier(train.classes, prompt)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(dataset, batch_size=100)):\n",
    "            features = model.encode_image(images.to(device))\n",
    "\n",
    "            features /= features.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            all_features.append(features @ weights)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "# Calculate the image features\n",
    "train_features, train_labels = get_features(train)\n",
    "test_features, test_labels = get_features(test)\n",
    "\n",
    "# Perform logistic regression\n",
    "classifier = LogisticRegression(penalty='l2', random_state=0, C=0.1, max_iter=3000, verbose=1)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(float)) * 100.\n",
    "print(f\"Accuracy = {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40559110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
